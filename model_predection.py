import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import roc_auc_score
import joblib

# 1ï¸âƒ£ í•™ìŠµ ë°ì´í„° ë¡œë“œ
train_file = "feature_engineered_data.csv"
df_train = pd.read_csv(train_file, encoding='utf-8')

# 2ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
test_file = "test.csv"
df_test = pd.read_csv(test_file, encoding='utf-8')

# 3ï¸âƒ£ X, y ë°ì´í„° ë¶„í• 
target = 'ì„ì‹  ì„±ê³µ ì—¬ë¶€'  # ì˜ˆì¸¡í•  ëª©í‘œ ë³€ìˆ˜
drop_cols = ['ID', 'ì‹œìˆ  ì‹œê¸° ì½”ë“œ']  # í•™ìŠµì— í•„ìš” ì—†ëŠ” ë³€ìˆ˜

# í•™ìŠµ ë°ì´í„° (Train)
X_train = df_train.drop(columns=[target] + drop_cols, errors='ignore')
y_train = df_train[target]

# í…ŒìŠ¤íŠ¸ ë°ì´í„° (Test)
X_test = df_test.drop(columns=drop_cols, errors='ignore')  # ì˜ˆì¸¡ì„ ìœ„í•œ ì…ë ¥ ë°ì´í„°
y_test = df_test[target] if target in df_test.columns else None  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì •ë‹µì´ ìˆëŠ” ê²½ìš°

# â˜…â˜… ì¶”ê°€: ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ (ë¬¸ìí˜• ë³€ìˆ˜ê°€ ìˆì„ ê²½ìš° ì›-í•« ì¸ì½”ë”©)
X_train = pd.get_dummies(X_train, drop_first=True)
X_test = pd.get_dummies(X_test, drop_first=True)

# í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì»¬ëŸ¼ ì •ë ¬ (ëˆ„ë½ëœ ì»¬ëŸ¼ì´ ìˆì„ ê²½ìš° ì •ë ¬ ë° NaN ì±„ìš°ê¸°)
X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)

# 4ï¸âƒ£ ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
models = {
    "RandomForest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "CatBoost": CatBoostClassifier(verbose=0, random_state=42)
}

results = {}
for model_name, model in models.items():
    print(f"\nğŸš€ {model_name} ëª¨ë¸ í•™ìŠµ ì¤‘...")
    model.fit(X_train, y_train)  # ëª¨ë¸ í•™ìŠµ

    # ì˜ˆì¸¡ í™•ë¥  (Test ë°ì´í„°) - ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼
    y_pred_proba = np.round(model.predict_proba(X_test)[:, 1], 2)

    # ğŸ”¹ ì œì¶œ íŒŒì¼ ì–‘ì‹ì— ë§ê²Œ ì»¬ëŸ¼ëª… ìˆ˜ì •: "Prediction" â†’ "probability"
    submission_data = {"ID": df_test["ID"], "probability": y_pred_proba}
    submission_df = pd.DataFrame(submission_data)

    file_name = f"model_predictions_{model_name}.csv"
    submission_df.to_csv(file_name, index=False, encoding="utf-8-sig")
    print(f"ğŸ“Œ {model_name} ì˜ˆì¸¡ í™•ë¥  ì €ì¥ ì™„ë£Œ: {file_name}")

    # ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì •ë‹µì´ ìˆì„ ê²½ìš°)
    if y_test is not None:
        try:
            roc_auc = roc_auc_score(y_test, y_pred_proba)
            results[model_name] = {"ROC-AUC": roc_auc}
            print(f"âœ… {model_name} í…ŒìŠ¤íŠ¸ ROC-AUC: {roc_auc:.4f}")
        except Exception as e:
            print(f"âš ï¸ {model_name} ROC-AUC ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ëª¨ë¸ ì €ì¥
    model_path = f"{model_name}_model.pkl"
    joblib.dump(model, model_path)
    print(f"ğŸ“Œ {model_name} ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

# 5ï¸âƒ£ ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼ ì €ì¥
if results:
    results_df = pd.DataFrame(results).T
    results_df.to_csv("model_performance.csv", encoding="utf-8-sig")
    print("\nğŸ“Œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ê°€ 'model_performance.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
